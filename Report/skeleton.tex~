\input{base.tex}


\begin{document}

\title{Visual illusions and interactions in biologically inspired neural networks. Analyzing perception of tilt}

\author{Martin Andreev Asenov}

% to choose your course
% please un-comment just one of the following
\course{Artificial Intelligence and Computer Science}
%\course{Artificial Intelligence and Software Engineering}
%\course{Artificial Intelligence and Mathematics}
%\course{Artificial Intelligence and Psychology }   
%\course{Artificial Intelligence with Psychology }   
%\course{Linguistics and Artificial Intelligence}    
%\course{Computer Science}
%\course{Software Engineering}
%\course{Computer Science and Electronics}    
%\course{Electronics and Software Engineering}    
%\course{Computer Science and Management Science}    
%\course{Computer Science and Mathematics}
%\course{Computer Science and Physics}  
%\course{Computer Science and Statistics}    

% to choose your report type
% please un-comment just one of the following
%\project{Undergraduate Dissertation} % CS&E, E&SE, AI&L
%\project{Undergraduate Thesis} % AI%Psy
\project{4th Year Project Report}

\date{\today}

\abstract{
Human vision has been extensively studied both at a single cell level as well as on a higher cortical level, using different techniques like EEG, fMRI, Extracellular and Intracellular recordings as well as optical imaging. A lot of work has been done in analyzing edge detection and representation of a line in our visual cortex. Different neurons are tuned for specific orientation and specific part of our visual field. Based on those neurons we get multiple responses for those parts of our visual field, which combined together give us our perception of tilt.

Models have been developed, which explain variety of visual illusions we experience, including pop-out and tilt illusions. However usually these models calculate the the perceived orientation in a static model, depending only on the current orientations in our visual field. The effect on those connections has not been tested in a full dynamic model, where groups of neurons keep acting on each other. This paper aims to explore a dynamic model, what effects does it have on our overall perception of tilt, and verify the validity of existing models.  
}

\maketitle

\section*{Acknowledgements}
Acknowledgements go here. 

\tableofcontents

%\pagenumbering{arabic}


\chapter{Introduction}

This paper develops a model, based and built upon the one described in the recent elastica paper \cite{keemink2015unified}. Although there are models explaining similar phenomenas, illusions as effects separately, the neural model described claims to have all of those properties, unifying them in one model. However all the results obtained were obtained statically with only one pass through the model. As mentioned in further development, adding dynamics to some of the already presented illusions could lead to some interesting behavior.





\chapter{Background}

In explaining the model setup, it is important to first introduce some neuroscience terminology, used in the developed model. As one can imagine the visual cortex is utterly complex. We are focusing on the V1 cortex, analyzing the orientation selective neurons. Even though we are focusing on a specific neurons in only a part of our visual processing pipeline, we make even more simplifications in order to be able to analyze specific features of those neurons. 

\section{Visual field}





Visual field is the area we can see with our eyes. The initial information we receive is changes in light from our retina. This then gets processed by the lateral geniculate nucleus (LGN) and passed down to the Primary visual cortex (V1). V1 receives information about orientation information about the different parts of our visual field. 

\plotfigure{visual_fields}{Information processing from retina, LGN cells and V1 orientation selective cells}

Precisely how this information is processed in the main interest of this project. Most of the information we perceive is close to the central or foveal vision, which could lead to interesting behavior \cite{knight2008drastically}. However we will ignore this details in our experiments.

\plotfigure{RetinotopicMapping}{Test}

\section{Receptive fields}

One of the first records on the topic explains receptive fields as the part of visual field, which affect a specific neuron \cite{Hartline700}. An alternative, more general definition is a region of the sensory space, which can stimulate a given sensory neuron.  It was later discovered that time plays a role as well, making the definition more complicated \cite{deangelis1995receptive}. In general, outside of the visual cortex, a receptive field is defined as a region of the sensory space, which can stimulate a given sensory neuron. In our model, described later, we focus on the spatial and ignore the temporal separation of receptive fields.
The definition of receptive field of a neuron has evolved over time.

\plotfigure{F4large}{Test}

\section{Tuning curves}

Different orientation selective neurons are tuned for different orientation at a specific part of the visual field, defined by their receptive field. However they spike not only when the preferred orientation is presented, but also on similar to its preferred orientation. The intensity of spiking, when different orientations are presented, forms a bell shaped curve with a peak the preferred orientation of the neuron. 

\plotfigure{HubelWiesel}{Test}


\section{Population coding}

Our final perception of the orientation in a specific part of our visual field is based on the all the spiking of the neurons with that receptive field. Their directions and magnitude form vectors, which when added together give the final perceived orientation.

\plotfigure{populationCoding}{Test}  

\chapter{Design}

This paper implements simplified version of visual field, receptive fields, tuning curves and population coding in a recurrent neural network with orientation selective neurons. We start with a simple model with one receptive field, extend the model to multiple receptive fields, define limited and full connectivity and finally implement the elastica principle as well. In this section the different models are described in detail.

The input our model receives is a matrix of numbers from the interval $0-1$, representing different orientation from $0\degree$ to $180\degree$. The output has the same form and represents what orientations the model perceives.


\plottwofigures{input_random}{input_structure}{Visualization of sample input(output) to the model. (A) Random orientations. (B) All orientations from $0\degree$ to $180\degree$, for every $1.8\degree$.}

For every single orientation of the input (every single bar in fig.\ref{input_random}), we have different neurons tuned for different orientations (fig.\ref{neuron2}). 

\plotfigureS{neuron2}{Orientation selective neurons for a single orientation of our visual field. The nine neurons will spike with higher intensity, depending on the difference of the presented orientation and their preferred orientations. All the responses are combined, giving the final perceived orientation.}{.3}

As described in \cite{keemink2015unified}, we represent those responses as vectors, with direction their preferred orientation and magnitude, the strength of the response with respect to the stimuli. Summing those vectors gives us the perceived orientation. Although used for recording responses from different types of neurons, fig.\ref{populationCoding} shows how population coding works. Black vectors are neural activity from specific neurons, and the red vector is the sum of all those responses.

Even at this small scale, some experiments (described later) can be run, which show the relation between number of orientation selective neurons used and the accuracy of the perceived orientation.

Next we extend the model so we can feed two orientations and we have orientation selective neurons for the two orientations. We add recurrent connection between the neurons with the same preferred orientations, as showed in fig.\ref{neuron5}, (A), (B). This adds contextual modulation, as the perceived orientation of a single orientation in the visual field is influenced by the other one.

The firing rate of the pairs of same orientation selective neurons in the two visual fields is calculated by the differential equations:

\begin{equation}
\label{model11}
\tau_{syn}\cfrac{dr_{1}(t)}{dt}=-r_{1}(t)+in_{1}+w_{12}r_{2}
\end{equation}


\begin{equation}
\label{model12}
\tau_{syn}\cfrac{dr_{2}(t)}{dt}=-r_{2}(t)+in_{2}+w_{21}r_{1}
\end{equation}

where $\tau_{syn}$ is a constant, $\cfrac{dr_{1/2}(t)}{dt}$ is the change of the firing rate with respect to time, $r_{1/2}(t)$ is the current firing rate, $w_{12/21}$ is the strength between the neurons. $in_{1/2}$ is calculated from the tuning curve of the specific neuron for the  presented orientation. In our model we will use the von Mises function as in \cite{keemink2015unified}. The von Mises function has the following formula:

\eq{A\exp(k\cos(2\alpha_{pref} - \alpha_{actual}))}


The different values of $A$ and $k$ are again described in \cite{keemink2015unified}, but ultimately the function with the correct set of parameters gives us the similarly looking tuning curves as in fig.\ref{HubelWiesel}.

\begin{equation}
\tau_{syn}\cfrac{dr(t)}{dt}=-r(t)+in+\sum\sigma_{distance}\sigma_{orientation}r_{i}
\end{equation}

\plottwofigures{neuron5}{neuron3}{Two orientation, with limited connectivity between neurons}

Next we extend the model, so we can have any number of orientations (fig.\ref{neuron1}). Every neuron (except the ones at the end at the visual field) is connected with the eight closest neurons, which have the same preferred orientation as his (fig.\ref{neuron1}). We can extend the formulas \ref{model11} and \ref{model12} to:

\begin{equation}
\tau_{syn}\cfrac{dr(t)}{dt}=-r(t)+in+\sum wr_{i}
\end{equation}

 
\plotfigureS{neuron1}{Any number of orientations, with limited connectivity between neurons. *The connections for only one neuron are shown.}{0.7}

The final modification we do, on single neuron level, is to add full connectivity between all the neurons. We set the weights depending on the closeness of the neurons to each other, as well as the similarity of their preferred orientation. To explain how we setup the weights, let use an example. Let's have a $10x10$ visual field with different orientations, as in fig.\ref{input_random} and $9$ orientations selective neurons as shown in fig.\ref{neuron2}. We have $900$ neurons all together. We can setup $900x900$ weight matrix defining the connections between the neurons. 

Having some distance factor and the orientation factor as $\sigma_{distance}$ and $\sigma_{orientation}$ and for every two neurons $l$ and $m$ model the strength of the connection between them as:

\eq{d=\sqrt{{(i_{l}-i_{m})}^{2}+{{(j_{l}-j_{m})}^{2}}}}

\eq{\delta=min(mod(\alpha_{l}-\alpha_{m},1),mod(\alpha_{m}-\alpha_{l},1))}

\eq{w_{i,j}=w_{j,i}=\sigma_{distance}\cfrac{1}{exp(d)} + \sigma_{orientation}\cfrac{1}{exp(\delta)}}

The strength of the connection between every two neurons $l$ and $m$ is the same as the recurrent connection between $l$ and $m$, so the matrix is symmetric with respect to the main diagonal. The values along the main diagonals are $0$ (a neuron does not have a connection with itself). We can also notice the general trend of having highest values along the main diagonal and then smaller values the further away we go. This is true for different scales of our matrix - the full matrix (a), the first $100x100$ square (b) as well as the first $10x10$ square (c). The three different scales represent the change in orientation, horizontal and vertical position.



\plotfigures{weight1}{weight2}{weight3}{weight4}{Weight matrix for a full connectivity model. (A) Full weight matrix. (B) First 100 neurons. (C) First 10 neurons. (D) Scale of the values.}

\plotfiguresix{elastica1}{elastica2}{elastica3}{elastica4}{elastica5}{elastica6}{Elastica}{.7}




\chapter{Implementation}

(Notes)

Since the model is recursive and changes with respect to time, the output is not only $1$ matrix, but $\cfrac{t}{ts}$ number of matrices, where $t$ is the simulation time and $ts$ is the length of the time step.

\chapter{Evaluation}

\chapter{Conclusions}

% use the following and \cite{} as above if you use BibTeX
% otherwise generate bibtem entries
\bibliographystyle{plain}
\bibliography{mybib}

\end{document}
